{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Load Libs","metadata":{}},{"cell_type":"code","source":"import sys\n\nsys.path.append('../input/monai-v081/')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:05:12.342627Z","iopub.execute_input":"2022-07-03T05:05:12.343279Z","iopub.status.idle":"2022-07-03T05:05:12.375291Z","shell.execute_reply.started":"2022-07-03T05:05:12.343188Z","shell.execute_reply":"2022-07-03T05:05:12.374428Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import gc\nfrom glob import glob\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom monai.inferers import sliding_window_inference\nfrom monai.data import decollate_batch\nfrom monai.handlers.utils import from_engine\nfrom monai.networks.nets import UNet\nfrom torch.cuda.amp import GradScaler, autocast\nfrom tqdm import tqdm\nimport json","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:05:12.438223Z","iopub.execute_input":"2022-07-03T05:05:12.438869Z","iopub.status.idle":"2022-07-03T05:05:20.809290Z","shell.execute_reply.started":"2022-07-03T05:05:12.438840Z","shell.execute_reply":"2022-07-03T05:05:20.808408Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"WANDB\")\n    wandb.login(key=api_key)\n    anonymous = None\nexcept:\n    anonymous = \"must\"\n    print('To use your W&B account,\\nGo to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \\nGet your W&B access token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:05:20.811594Z","iopub.execute_input":"2022-07-03T05:05:20.811937Z","iopub.status.idle":"2022-07-03T05:05:41.556502Z","shell.execute_reply.started":"2022-07-03T05:05:20.811866Z","shell.execute_reply":"2022-07-03T05:05:41.555453Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"To use your W&B account,\nGo to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \nGet your W&B access token from here: https://wandb.ai/authorize\n","output_type":"stream"}]},{"cell_type":"code","source":"from monai.data import CacheDataset, DataLoader\nfrom monai.transforms import (\n    Compose,\n    Activations,\n    AsDiscrete,\n    Activationsd,\n    AsDiscreted,\n    KeepLargestConnectedComponentd,\n    Invertd,\n    LoadImage,\n    Transposed,\n    LoadImaged,\n    AddChanneld,\n    CastToTyped,\n    Lambdad,\n    Resized,\n    EnsureTyped,\n    SpatialPadd,\n    EnsureChannelFirstd,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:05:41.558964Z","iopub.execute_input":"2022-07-03T05:05:41.559538Z","iopub.status.idle":"2022-07-03T05:05:41.566757Z","shell.execute_reply.started":"2022-07-03T05:05:41.559479Z","shell.execute_reply":"2022-07-03T05:05:41.565835Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Prepare meta info.","metadata":{}},{"cell_type":"markdown","source":"### Thanks awsaf49, this section refers to:\nhttps://www.kaggle.com/code/awsaf49/uwmgi-2-5d-infer-pytorch","metadata":{}},{"cell_type":"code","source":"def get_metadata(row):\n    data = row['id'].split('_')\n    case = int(data[0].replace('case',''))\n    day = int(data[1].replace('day',''))\n    slice_ = int(data[-1])\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row\n\ndef path2info(row):\n    path = row['image_path']\n    data = path.split('/')\n    slice_ = int(data[-1].split('_')[1])\n    case = int(data[-3].split('_')[0].replace('case',''))\n    day = int(data[-3].split('_')[1].replace('day',''))\n    width = int(data[-1].split('_')[2])\n    height = int(data[-1].split('_')[3])\n    row['height'] = height\n    row['width'] = width\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:05:41.569724Z","iopub.execute_input":"2022-07-03T05:05:41.570400Z","iopub.status.idle":"2022-07-03T05:05:41.583119Z","shell.execute_reply.started":"2022-07-03T05:05:41.570342Z","shell.execute_reply":"2022-07-03T05:05:41.581884Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\nif not len(sub_df):\n    debug = True\n    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')[:1000*3]\n    sub_df = sub_df.drop(columns=['class','segmentation']).drop_duplicates()\nelse:\n    debug = False\n    sub_df = sub_df.drop(columns=['class','predicted']).drop_duplicates()\nsub_df = sub_df.apply(lambda x: get_metadata(x),axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:05:41.584782Z","iopub.execute_input":"2022-07-03T05:05:41.585259Z","iopub.status.idle":"2022-07-03T05:05:44.095313Z","shell.execute_reply.started":"2022-07-03T05:05:41.585185Z","shell.execute_reply":"2022-07-03T05:05:44.094368Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"if debug:\n    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/train/**/*png',recursive=True)\n#     paths = sorted(paths)\nelse:\n    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/test/**/*png',recursive=True)\n#     paths = sorted(paths)\npath_df = pd.DataFrame(paths, columns=['image_path'])\npath_df = path_df.apply(lambda x: path2info(x),axis=1)\npath_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:05:44.097341Z","iopub.execute_input":"2022-07-03T05:05:44.097836Z","iopub.status.idle":"2022-07-03T05:07:56.707092Z","shell.execute_reply.started":"2022-07-03T05:05:44.097795Z","shell.execute_reply":"2022-07-03T05:07:56.706210Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                          image_path  height  width  case  \\\n0  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n1  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n2  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n3  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n4  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n\n   day  slice  \n0   14      6  \n1   14     82  \n2   14    113  \n3   14     76  \n4   14    125  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>height</th>\n      <th>width</th>\n      <th>case</th>\n      <th>day</th>\n      <th>slice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n      <td>266</td>\n      <td>266</td>\n      <td>36</td>\n      <td>14</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n      <td>266</td>\n      <td>266</td>\n      <td>36</td>\n      <td>14</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n      <td>266</td>\n      <td>266</td>\n      <td>36</td>\n      <td>14</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n      <td>266</td>\n      <td>266</td>\n      <td>36</td>\n      <td>14</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n      <td>266</td>\n      <td>266</td>\n      <td>36</td>\n      <td>14</td>\n      <td>125</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Produce 3d data list for MONAI DataSet","metadata":{}},{"cell_type":"code","source":"test_df = sub_df.merge(path_df, on=['case','day','slice'], how='left')\ntest_df[\"case_id_str\"] = test_df[\"id\"].apply(lambda x: x.split(\"_\", 2)[0])\ntest_df[\"day_num_str\"] = test_df[\"id\"].apply(lambda x: x.split(\"_\", 2)[1])\ntest_df[\"slice_id\"] = test_df[\"id\"].apply(lambda x: x.split(\"_\", 2)[2])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:07:56.708482Z","iopub.execute_input":"2022-07-03T05:07:56.708767Z","iopub.status.idle":"2022-07-03T05:07:56.740617Z","shell.execute_reply.started":"2022-07-03T05:07:56.708728Z","shell.execute_reply":"2022-07-03T05:07:56.739749Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_data = []\n\nfor group in test_df.groupby([\"case_id_str\", \"day_num_str\"]):\n\n    case_id_str, day_num_str = group[0]\n    group_id = case_id_str + \"_\" + day_num_str\n    group_df = group[1].sort_values(\"slice_id\", ascending=True)\n    n_slices = group_df.shape[0]\n    group_slices, group_ids = [], []\n    for idx in range(n_slices):\n        slc = group_df.iloc[idx]\n        group_slices.append(slc.image_path)\n        group_ids.append(slc.id)\n    test_data.append({\"image\": group_slices, \"id\": group_ids})","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:07:56.741873Z","iopub.execute_input":"2022-07-03T05:07:56.742749Z","iopub.status.idle":"2022-07-03T05:07:56.942770Z","shell.execute_reply.started":"2022-07-03T05:07:56.742705Z","shell.execute_reply":"2022-07-03T05:07:56.941819Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Transforms, Dataset, DataLoader","metadata":{}},{"cell_type":"code","source":"class cfg:\n    img_size = (224, 224, 80)\n    in_channels = 1\n    out_channels = 4\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    weights = glob(\"../input/uw3dweights/unet_fold0_0.8789.pth\")\n    batch_size = 1\n    sw_batch_size = 4","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:07:56.944142Z","iopub.execute_input":"2022-07-03T05:07:56.945131Z","iopub.status.idle":"2022-07-03T05:07:57.018878Z","shell.execute_reply.started":"2022-07-03T05:07:56.945070Z","shell.execute_reply":"2022-07-03T05:07:57.017792Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"for i in cfg.weights:\n    print(i)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:07:57.024356Z","iopub.execute_input":"2022-07-03T05:07:57.024973Z","iopub.status.idle":"2022-07-03T05:07:57.032157Z","shell.execute_reply.started":"2022-07-03T05:07:57.024939Z","shell.execute_reply":"2022-07-03T05:07:57.031108Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"../input/uw3dweights/unet_fold0_0.8789.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transforms = Compose(\n    [\n        LoadImaged(keys=\"image\"), # d, h, w\n        AddChanneld(keys=\"image\"), # c, d, h, w\n        Transposed(keys=\"image\", indices=[0, 2, 3, 1]), # c, w, h, d\n        Lambdad(keys=\"image\", func=lambda x: x / x.max()),\n#         SpatialPadd(keys=\"image\", spatial_size=cfg.img_size),  # in case less than 80 slices\n        EnsureTyped(keys=\"image\", dtype=torch.float32),\n    ]\n)\n\ntest_ds = CacheDataset(\n        data=test_data,\n        transform=test_transforms,\n        cache_rate=0.0,\n        num_workers=2,\n    )\n\ntest_dataloader = DataLoader(\n    test_ds,\n    batch_size=cfg.batch_size,\n    num_workers=2,\n    pin_memory=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:07:57.033516Z","iopub.execute_input":"2022-07-03T05:07:57.034356Z","iopub.status.idle":"2022-07-03T05:07:57.047364Z","shell.execute_reply.started":"2022-07-03T05:07:57.034311Z","shell.execute_reply":"2022-07-03T05:07:57.046426Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Network","metadata":{}},{"cell_type":"code","source":"model = UNet(\n    spatial_dims=3,\n    in_channels=cfg.in_channels,\n    out_channels=cfg.out_channels,\n    channels=(16, 32, 64, 128, 256),\n    strides=(2, 2, 2, 2),\n    kernel_size=3,\n    up_kernel_size=3,\n    num_res_units=2,\n    act=\"PRELU\",\n    norm=\"BATCH\",\n    dropout=0.2,\n    bias=True,\n    dimensions=None,\n).to(cfg.device)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:07:57.049706Z","iopub.execute_input":"2022-07-03T05:07:57.051522Z","iopub.status.idle":"2022-07-03T05:08:00.739689Z","shell.execute_reply.started":"2022-07-03T05:07:57.051434Z","shell.execute_reply":"2022-07-03T05:08:00.738754Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Infer","metadata":{}},{"cell_type":"code","source":"# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    \"\"\" TBD\n    \n    Args:\n        img (np.array): \n            - 1 indicating mask\n            - 0 indicating background\n    \n    Returns: \n        run length as string formated\n    \"\"\"\n    \n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:08:00.741343Z","iopub.execute_input":"2022-07-03T05:08:00.741650Z","iopub.status.idle":"2022-07-03T05:08:00.749119Z","shell.execute_reply.started":"2022-07-03T05:08:00.741610Z","shell.execute_reply":"2022-07-03T05:08:00.747773Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"outputs = []\n\npost_pred = Compose([\n    Activations(sigmoid=True),\n    AsDiscrete(threshold=0.5)\n])\n\nmodel.eval()\ntorch.set_grad_enabled(False)\nprogress_bar = tqdm(range(len(test_dataloader)))\nval_it = iter(test_dataloader)\nfor itr in progress_bar:\n    batch = next(val_it)\n    test_inputs = batch[\"image\"].to(cfg.device)\n\n    pred_all = []\n    for weights in cfg.weights:\n        model.load_state_dict(torch.load(weights))\n        pred = sliding_window_inference(test_inputs, cfg.img_size, cfg.sw_batch_size, model)\n        pred_all.append(pred)\n        # do 4 tta\n        for dims in [[2], [3], [2, 3]]:\n            flip_pred = sliding_window_inference(torch.flip(test_inputs, dims=dims), cfg.img_size, cfg.sw_batch_size, model)\n            flip_pred = torch.flip(flip_pred, dims=dims)\n            pred_all.append(flip_pred)\n    pred_all = torch.mean(torch.stack(pred_all), dim=0)[0]\n    pred_all = post_pred(pred_all)[1:]\n    # c, w, h, d to d, c, h, w\n    pred_all = torch.permute(pred_all, [3, 0, 2, 1]).cpu().numpy().astype(np.uint8)\n    id_outputs = from_engine([\"id\"])(batch)[0]\n\n    for test_output, id_output in zip(pred_all, id_outputs):\n        id_name = id_output[0]\n        lb, sb, st = test_output\n        outputs.append([id_name, \"large_bowel\", lb])\n        outputs.append([id_name, \"small_bowel\", sb])\n        outputs.append([id_name, \"stomach\", st])\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:08:00.750647Z","iopub.execute_input":"2022-07-03T05:08:00.751508Z","iopub.status.idle":"2022-07-03T05:08:22.167739Z","shell.execute_reply.started":"2022-07-03T05:08:00.751444Z","shell.execute_reply":"2022-07-03T05:08:22.166527Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"100%|██████████| 7/7 [00:21<00:00,  3.06s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"  class cfg:\n    img_size = (224, 224, 80)\n    in_channels = 1\n    out_channels = 3\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    weights = glob(\"../input/uw3dweights/large_unet_fold0_0.9024.pth\")\n    batch_size = 1\n    sw_batch_size = 4","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:08:22.170751Z","iopub.execute_input":"2022-07-03T05:08:22.172601Z","iopub.status.idle":"2022-07-03T05:08:22.182026Z","shell.execute_reply.started":"2022-07-03T05:08:22.172538Z","shell.execute_reply":"2022-07-03T05:08:22.180954Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"test_transforms = Compose(\n    [\n        LoadImaged(keys=\"image\"), # d, h, w\n        AddChanneld(keys=\"image\"), # c, d, h, w\n        Transposed(keys=\"image\", indices=[0, 2, 3, 1]), # c, w, h, d\n        Lambdad(keys=\"image\", func=lambda x: x / x.max()),\n#         SpatialPadd(keys=\"image\", spatial_size=cfg.img_size),  # in case less than 80 slices\n        EnsureTyped(keys=\"image\", dtype=torch.float32),\n    ]\n)\n\ntest_ds = CacheDataset(\n        data=test_data,\n        transform=test_transforms,\n        cache_rate=0.0,\n        num_workers=2,\n    )\n\ntest_dataloader = DataLoader(\n    test_ds,\n    batch_size=cfg.batch_size,\n    num_workers=2,\n    pin_memory=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:08:22.183753Z","iopub.execute_input":"2022-07-03T05:08:22.184116Z","iopub.status.idle":"2022-07-03T05:08:22.196753Z","shell.execute_reply.started":"2022-07-03T05:08:22.184073Z","shell.execute_reply":"2022-07-03T05:08:22.195407Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = UNet(\n    spatial_dims=3,\n    in_channels=cfg.in_channels,\n    out_channels=cfg.out_channels,\n    channels=(32, 64, 128, 256, 512),\n    strides=(2, 2, 2, 2),\n    kernel_size=3,\n    up_kernel_size=3,\n    num_res_units=2,\n    act=\"PRELU\",\n    norm=\"BATCH\",\n    dropout=0.2,\n    bias=True,\n    dimensions=None,\n).to(cfg.device)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:08:22.198193Z","iopub.execute_input":"2022-07-03T05:08:22.198645Z","iopub.status.idle":"2022-07-03T05:08:22.423309Z","shell.execute_reply.started":"2022-07-03T05:08:22.198601Z","shell.execute_reply":"2022-07-03T05:08:22.422229Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"outputs2 = []\n\npost_pred = Compose([\n    Activations(sigmoid=True),\n    AsDiscrete(threshold=0.5)\n])\n\nmodel.eval()\ntorch.set_grad_enabled(False)\nprogress_bar = tqdm(range(len(test_dataloader)))\nval_it = iter(test_dataloader)\nfor itr in progress_bar:\n    batch = next(val_it)\n    test_inputs = batch[\"image\"].to(cfg.device)\n\n    pred_all = []\n    for weights in cfg.weights:\n        model.load_state_dict(torch.load(weights))\n        pred = sliding_window_inference(test_inputs, cfg.img_size, cfg.sw_batch_size, model)\n        pred_all.append(pred)\n        # do 4 tta\n        for dims in [[2], [3], [2, 3]]:\n            flip_pred = sliding_window_inference(torch.flip(test_inputs, dims=dims), cfg.img_size, cfg.sw_batch_size, model)\n            flip_pred = torch.flip(flip_pred, dims=dims)\n            pred_all.append(flip_pred)\n    pred_all = torch.mean(torch.stack(pred_all), dim=0)[0]\n    pred_all = post_pred(pred_all)\n    # c, w, h, d to d, c, h, w\n    pred_all = torch.permute(pred_all, [3, 0, 2, 1]).cpu().numpy().astype(np.uint8)\n    id_outputs2 = from_engine([\"id\"])(batch)[0]\n\n    for test_output2, id_output2 in zip(pred_all, id_outputs2):\n        id_name = id_output2[0]\n        lb, sb, st = test_output2\n        outputs2.append([id_name, \"large_bowel\", lb])\n        outputs2.append([id_name, \"small_bowel\", sb])\n        outputs2.append([id_name, \"stomach\", st])\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:08:22.424938Z","iopub.execute_input":"2022-07-03T05:08:22.425548Z","iopub.status.idle":"2022-07-03T05:08:45.100942Z","shell.execute_reply.started":"2022-07-03T05:08:22.425503Z","shell.execute_reply":"2022-07-03T05:08:45.099480Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|██████████| 7/7 [00:22<00:00,  3.24s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"submit1 = pd.DataFrame(data=np.array(outputs), columns=[\"id\", \"class1\", \"predicted1\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:20:58.534145Z","iopub.execute_input":"2022-07-03T05:20:58.534501Z","iopub.status.idle":"2022-07-03T05:20:58.547277Z","shell.execute_reply.started":"2022-07-03T05:20:58.534470Z","shell.execute_reply":"2022-07-03T05:20:58.546103Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"}]},{"cell_type":"code","source":"submit2 = pd.DataFrame(data=np.array(outputs2), columns=[\"id\", \"class2\", \"predicted2\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:21:00.457517Z","iopub.execute_input":"2022-07-03T05:21:00.457827Z","iopub.status.idle":"2022-07-03T05:21:00.469101Z","shell.execute_reply.started":"2022-07-03T05:21:00.457797Z","shell.execute_reply":"2022-07-03T05:21:00.467985Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"}]},{"cell_type":"code","source":"  class cfg:\n    img_size = (224, 224, 80)\n    in_channels = 1\n    out_channels = 4\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    weights = glob(\"../input/uw3dweights/unet_fold0_0.8932.pth\")\n    batch_size = 1\n    sw_batch_size = 4","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:08:45.158074Z","iopub.execute_input":"2022-07-03T05:08:45.158586Z","iopub.status.idle":"2022-07-03T05:08:45.172295Z","shell.execute_reply.started":"2022-07-03T05:08:45.158541Z","shell.execute_reply":"2022-07-03T05:08:45.170869Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"test_transforms = Compose(\n    [\n        LoadImaged(keys=\"image\"), # d, h, w\n        AddChanneld(keys=\"image\"), # c, d, h, w\n        Transposed(keys=\"image\", indices=[0, 2, 3, 1]), # c, w, h, d\n        Lambdad(keys=\"image\", func=lambda x: x / x.max()),\n#         SpatialPadd(keys=\"image\", spatial_size=cfg.img_size),  # in case less than 80 slices\n        EnsureTyped(keys=\"image\", dtype=torch.float32),\n    ]\n)\n\ntest_ds = CacheDataset(\n        data=test_data,\n        transform=test_transforms,\n        cache_rate=0.0,\n        num_workers=2,\n    )\n\ntest_dataloader = DataLoader(\n    test_ds,\n    batch_size=cfg.batch_size,\n    num_workers=2,\n    pin_memory=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:08:45.174357Z","iopub.execute_input":"2022-07-03T05:08:45.175117Z","iopub.status.idle":"2022-07-03T05:08:45.193346Z","shell.execute_reply.started":"2022-07-03T05:08:45.174910Z","shell.execute_reply":"2022-07-03T05:08:45.192077Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model = UNet(\n    spatial_dims=3,\n    in_channels=cfg.in_channels,\n    out_channels=cfg.out_channels,\n    channels=(16, 32, 64, 128, 256),\n    strides=(2, 2, 2, 2),\n    kernel_size=3,\n    up_kernel_size=3,\n    num_res_units=2,\n    act=\"PRELU\",\n    norm=\"BATCH\",\n    dropout=0.2,\n    bias=True,\n    dimensions=None,\n).to(cfg.device)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:08:45.199227Z","iopub.execute_input":"2022-07-03T05:08:45.199628Z","iopub.status.idle":"2022-07-03T05:08:45.354025Z","shell.execute_reply.started":"2022-07-03T05:08:45.199572Z","shell.execute_reply":"2022-07-03T05:08:45.352814Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"outputs3 = []\n\npost_pred = Compose([\n    Activations(sigmoid=True),\n    AsDiscrete(threshold=0.5)\n])\n\nmodel.eval()\ntorch.set_grad_enabled(False)\nprogress_bar = tqdm(range(len(test_dataloader)))\nval_it = iter(test_dataloader)\nfor itr in progress_bar:\n    batch = next(val_it)\n    test_inputs = batch[\"image\"].to(cfg.device)\n\n    pred_all = []\n    for weights in cfg.weights:\n        model.load_state_dict(torch.load(weights))\n        pred = sliding_window_inference(test_inputs, cfg.img_size, cfg.sw_batch_size, model)\n        pred_all.append(pred)\n        # do 4 tta\n        for dims in [[2], [3], [2, 3]]:\n            flip_pred = sliding_window_inference(torch.flip(test_inputs, dims=dims), cfg.img_size, cfg.sw_batch_size, model)\n            flip_pred = torch.flip(flip_pred, dims=dims)\n            pred_all.append(flip_pred)\n    pred_all = torch.mean(torch.stack(pred_all), dim=0)[0]\n    pred_all = post_pred(pred_all)[1:]\n    # c, w, h, d to d, c, h, w\n    pred_all = torch.permute(pred_all, [3, 0, 2, 1]).cpu().numpy().astype(np.uint8)\n    id_outputs3 = from_engine([\"id\"])(batch)[0]\n\n    for test_output3, id_output3 in zip(pred_all, id_outputs3):\n        id_name = id_output3[0]\n        lb, sb, st = test_output3\n        outputs3.append([id_name, \"large_bowel\", lb])\n        outputs3.append([id_name, \"small_bowel\", sb])\n        outputs3.append([id_name, \"stomach\", st])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:08:45.360559Z","iopub.execute_input":"2022-07-03T05:08:45.360851Z","iopub.status.idle":"2022-07-03T05:09:00.422625Z","shell.execute_reply.started":"2022-07-03T05:08:45.360813Z","shell.execute_reply":"2022-07-03T05:09:00.421312Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"100%|██████████| 7/7 [00:15<00:00,  2.15s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"submit3 = pd.DataFrame(data=np.array(outputs3), columns=[\"id\", \"class3\", \"predicted3\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:21:07.172815Z","iopub.execute_input":"2022-07-03T05:21:07.173483Z","iopub.status.idle":"2022-07-03T05:21:07.185518Z","shell.execute_reply.started":"2022-07-03T05:21:07.173446Z","shell.execute_reply":"2022-07-03T05:21:07.184221Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"}]},{"cell_type":"code","source":"class cfg:\n    img_size = (224, 224, 80)\n    in_channels = 1\n    out_channels = 4\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    weights = glob(\"../input/uw3dweights/unet_fold0_0.9108.pth\")\n    batch_size = 1\n    sw_batch_size = 4","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:00.443262Z","iopub.execute_input":"2022-07-03T05:09:00.443693Z","iopub.status.idle":"2022-07-03T05:09:00.454157Z","shell.execute_reply.started":"2022-07-03T05:09:00.443651Z","shell.execute_reply":"2022-07-03T05:09:00.453098Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"test_transforms = Compose(\n    [\n        LoadImaged(keys=\"image\"), # d, h, w\n        AddChanneld(keys=\"image\"), # c, d, h, w\n        Transposed(keys=\"image\", indices=[0, 2, 3, 1]), # c, w, h, d\n        Lambdad(keys=\"image\", func=lambda x: x / x.max()),\n#         SpatialPadd(keys=\"image\", spatial_size=cfg.img_size),  # in case less than 80 slices\n        EnsureTyped(keys=\"image\", dtype=torch.float32),\n    ]\n)\n\ntest_ds = CacheDataset(\n        data=test_data,\n        transform=test_transforms,\n        cache_rate=0.0,\n        num_workers=2,\n    )\n\ntest_dataloader = DataLoader(\n    test_ds,\n    batch_size=cfg.batch_size,\n    num_workers=2,\n    pin_memory=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:00.456012Z","iopub.execute_input":"2022-07-03T05:09:00.458746Z","iopub.status.idle":"2022-07-03T05:09:00.468749Z","shell.execute_reply.started":"2022-07-03T05:09:00.458697Z","shell.execute_reply":"2022-07-03T05:09:00.467443Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model = UNet(\n    spatial_dims=3,\n    in_channels=cfg.in_channels,\n    out_channels=cfg.out_channels,\n    channels=(16, 32, 64, 128, 256),\n    strides=(2, 2, 2, 2),\n    kernel_size=3,\n    up_kernel_size=3,\n    num_res_units=2,\n    act=\"PRELU\",\n    norm=\"BATCH\",\n    dropout=0.2,\n    bias=True,\n    dimensions=None,\n).to(cfg.device)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:00.477805Z","iopub.execute_input":"2022-07-03T05:09:00.480136Z","iopub.status.idle":"2022-07-03T05:09:00.560221Z","shell.execute_reply.started":"2022-07-03T05:09:00.480101Z","shell.execute_reply":"2022-07-03T05:09:00.559321Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"outputs4 = []\n\npost_pred = Compose([\n    Activations(sigmoid=True),\n    AsDiscrete(threshold=0.5)\n])\n\nmodel.eval()\ntorch.set_grad_enabled(False)\nprogress_bar = tqdm(range(len(test_dataloader)))\nval_it = iter(test_dataloader)\nfor itr in progress_bar:\n    batch = next(val_it)\n    test_inputs = batch[\"image\"].to(cfg.device)\n\n    pred_all = []\n    for weights in cfg.weights:\n        model.load_state_dict(torch.load(weights))\n        pred = sliding_window_inference(test_inputs, cfg.img_size, cfg.sw_batch_size, model)\n        pred_all.append(pred)\n        # do 4 tta\n        for dims in [[2], [3], [2, 3]]:\n            flip_pred = sliding_window_inference(torch.flip(test_inputs, dims=dims), cfg.img_size, cfg.sw_batch_size, model)\n            flip_pred = torch.flip(flip_pred, dims=dims)\n            pred_all.append(flip_pred)\n    pred_all = torch.mean(torch.stack(pred_all), dim=0)[0]\n    pred_all = post_pred(pred_all)[1:]\n    # c, w, h, d to d, c, h, w\n    pred_all = torch.permute(pred_all, [3, 0, 2, 1]).cpu().numpy().astype(np.uint8)\n    id_outputs4 = from_engine([\"id\"])(batch)[0]\n\n    for test_output4, id_output4 in zip(pred_all, id_outputs4):\n        id_name = id_output4[0]\n        lb, sb, st = test_output4\n        outputs4.append([id_name, \"large_bowel\", lb])\n        outputs4.append([id_name, \"small_bowel\", sb])\n        outputs4.append([id_name, \"stomach\", st])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:00.561841Z","iopub.execute_input":"2022-07-03T05:09:00.562215Z","iopub.status.idle":"2022-07-03T05:09:15.484172Z","shell.execute_reply.started":"2022-07-03T05:09:00.562173Z","shell.execute_reply":"2022-07-03T05:09:15.482992Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"100%|██████████| 7/7 [00:14<00:00,  2.13s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"submit4 = pd.DataFrame(data=np.array(outputs4), columns=[\"id\", \"class4\", \"predicted4\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:21:14.121338Z","iopub.execute_input":"2022-07-03T05:21:14.121691Z","iopub.status.idle":"2022-07-03T05:21:14.133834Z","shell.execute_reply.started":"2022-07-03T05:21:14.121659Z","shell.execute_reply":"2022-07-03T05:21:14.132692Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"}]},{"cell_type":"code","source":"  class cfg:\n    img_size = (224, 224, 80)\n    in_channels = 1\n    out_channels = 4\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    weights = glob(\"../input/uw3dweights/unet_fold0_new_metric_0.8925.pth\")\n    batch_size = 1\n    sw_batch_size = 4","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:15.504070Z","iopub.execute_input":"2022-07-03T05:09:15.505263Z","iopub.status.idle":"2022-07-03T05:09:15.518404Z","shell.execute_reply.started":"2022-07-03T05:09:15.505205Z","shell.execute_reply":"2022-07-03T05:09:15.517453Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"test_transforms = Compose(\n    [\n        LoadImaged(keys=\"image\"), # d, h, w\n        AddChanneld(keys=\"image\"), # c, d, h, w\n        Transposed(keys=\"image\", indices=[0, 2, 3, 1]), # c, w, h, d\n        Lambdad(keys=\"image\", func=lambda x: x / x.max()),\n#         SpatialPadd(keys=\"image\", spatial_size=cfg.img_size),  # in case less than 80 slices\n        EnsureTyped(keys=\"image\", dtype=torch.float32),\n    ]\n)\n\ntest_ds = CacheDataset(\n        data=test_data,\n        transform=test_transforms,\n        cache_rate=0.0,\n        num_workers=2,\n    )\n\ntest_dataloader = DataLoader(\n    test_ds,\n    batch_size=cfg.batch_size,\n    num_workers=2,\n    pin_memory=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:15.520075Z","iopub.execute_input":"2022-07-03T05:09:15.520665Z","iopub.status.idle":"2022-07-03T05:09:15.533177Z","shell.execute_reply.started":"2022-07-03T05:09:15.520609Z","shell.execute_reply":"2022-07-03T05:09:15.532137Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model = UNet(\n    spatial_dims=3,\n    in_channels=cfg.in_channels,\n    out_channels=cfg.out_channels,\n    channels=(16, 32, 64, 128, 256),\n    strides=(2, 2, 2, 2),\n    kernel_size=3,\n    up_kernel_size=3,\n    num_res_units=2,\n    act=\"PRELU\",\n    norm=\"BATCH\",\n    dropout=0.2,\n    bias=True,\n    dimensions=None,\n).to(cfg.device)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:15.535153Z","iopub.execute_input":"2022-07-03T05:09:15.535504Z","iopub.status.idle":"2022-07-03T05:09:15.618250Z","shell.execute_reply.started":"2022-07-03T05:09:15.535462Z","shell.execute_reply":"2022-07-03T05:09:15.617272Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"outputs5 = []\n\npost_pred = Compose([\n    Activations(sigmoid=True),\n    AsDiscrete(threshold=0.5)\n])\n\nmodel.eval()\ntorch.set_grad_enabled(False)\nprogress_bar = tqdm(range(len(test_dataloader)))\nval_it = iter(test_dataloader)\nfor itr in progress_bar:\n    batch = next(val_it)\n    test_inputs = batch[\"image\"].to(cfg.device)\n\n    pred_all = []\n    for weights in cfg.weights:\n        model.load_state_dict(torch.load(weights))\n        pred = sliding_window_inference(test_inputs, cfg.img_size, cfg.sw_batch_size, model)\n        pred_all.append(pred)\n        # do 4 tta\n        for dims in [[2], [3], [2, 3]]:\n            flip_pred = sliding_window_inference(torch.flip(test_inputs, dims=dims), cfg.img_size, cfg.sw_batch_size, model)\n            flip_pred = torch.flip(flip_pred, dims=dims)\n            pred_all.append(flip_pred)\n    pred_all = torch.mean(torch.stack(pred_all), dim=0)[0]\n    pred_all = post_pred(pred_all)[1:]\n    # c, w, h, d to d, c, h, w\n    pred_all = torch.permute(pred_all, [3, 0, 2, 1]).cpu().numpy().astype(np.uint8)\n    id_outputs5 = from_engine([\"id\"])(batch)[0]\n\n    for test_output5, id_output5 in zip(pred_all, id_outputs5):\n        id_name = id_output5[0]\n        lb, sb, st = test_output5\n        outputs5.append([id_name, \"large_bowel\", lb])\n        outputs5.append([id_name, \"small_bowel\", sb])\n        outputs5.append([id_name, \"stomach\", st])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:15.619988Z","iopub.execute_input":"2022-07-03T05:09:15.620378Z","iopub.status.idle":"2022-07-03T05:09:30.482064Z","shell.execute_reply.started":"2022-07-03T05:09:15.620338Z","shell.execute_reply":"2022-07-03T05:09:30.480921Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"100%|██████████| 7/7 [00:14<00:00,  2.12s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"lb.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:30.484674Z","iopub.execute_input":"2022-07-03T05:09:30.485906Z","iopub.status.idle":"2022-07-03T05:09:30.495494Z","shell.execute_reply.started":"2022-07-03T05:09:30.485814Z","shell.execute_reply":"2022-07-03T05:09:30.494446Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(266, 266)"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"a = submit1.iloc[146, :].predicted\nfor i in range(len(a)):\n    s = set(a[i])\n    if len(s) > 1:\n        print(s)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:30.496933Z","iopub.execute_input":"2022-07-03T05:09:30.497603Z","iopub.status.idle":"2022-07-03T05:09:30.510798Z","shell.execute_reply.started":"2022-07-03T05:09:30.497556Z","shell.execute_reply":"2022-07-03T05:09:30.509422Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"'a = submit1.iloc[146, :].predicted\\nfor i in range(len(a)):\\n    s = set(a[i])\\n    if len(s) > 1:\\n        print(s)'"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"import matplotlib.pyplot as plt\nplt.imshow(a)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:30.512318Z","iopub.execute_input":"2022-07-03T05:09:30.512845Z","iopub.status.idle":"2022-07-03T05:09:30.523546Z","shell.execute_reply.started":"2022-07-03T05:09:30.512802Z","shell.execute_reply":"2022-07-03T05:09:30.522438Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'import matplotlib.pyplot as plt\\nplt.imshow(a)'"},"metadata":{}}]},{"cell_type":"code","source":"sb.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:30.525025Z","iopub.execute_input":"2022-07-03T05:09:30.526011Z","iopub.status.idle":"2022-07-03T05:09:30.537207Z","shell.execute_reply.started":"2022-07-03T05:09:30.525964Z","shell.execute_reply":"2022-07-03T05:09:30.536036Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(266, 266)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit5 = pd.DataFrame(data=np.array(outputs5), columns=[\"id\", \"class5\", \"predicted5\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:21:26.693220Z","iopub.execute_input":"2022-07-03T05:21:26.694001Z","iopub.status.idle":"2022-07-03T05:21:26.707155Z","shell.execute_reply.started":"2022-07-03T05:21:26.693959Z","shell.execute_reply":"2022-07-03T05:21:26.706066Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"}]},{"cell_type":"code","source":"#submit1[submit1[\"predicted\"] != '']","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:30.557518Z","iopub.execute_input":"2022-07-03T05:09:30.558087Z","iopub.status.idle":"2022-07-03T05:09:30.567946Z","shell.execute_reply.started":"2022-07-03T05:09:30.558045Z","shell.execute_reply":"2022-07-03T05:09:30.566828Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit2[submit2[\"predicted2\"]!=\"\"]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:21:38.439870Z","iopub.execute_input":"2022-07-03T05:21:38.440160Z","iopub.status.idle":"2022-07-03T05:21:39.749408Z","shell.execute_reply.started":"2022-07-03T05:21:38.440115Z","shell.execute_reply":"2022-07-03T05:21:39.748417Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:73: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  result = libops.scalar_compare(x.ravel(), y, op)\n","output_type":"stream"},{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"                           id       class2  \\\n0     case123_day0_slice_0001  large_bowel   \n1     case123_day0_slice_0001  small_bowel   \n2     case123_day0_slice_0001      stomach   \n3     case123_day0_slice_0002  large_bowel   \n4     case123_day0_slice_0002  small_bowel   \n...                       ...          ...   \n2995  case77_day20_slice_0143  small_bowel   \n2996  case77_day20_slice_0143      stomach   \n2997  case77_day20_slice_0144  large_bowel   \n2998  case77_day20_slice_0144  small_bowel   \n2999  case77_day20_slice_0144      stomach   \n\n                                             predicted2  \n0     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n1     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n2     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n3     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n4     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n...                                                 ...  \n2995  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n2996  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n2997  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n2998  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n2999  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n\n[3000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class2</th>\n      <th>predicted2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>case123_day0_slice_0001</td>\n      <td>large_bowel</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>case123_day0_slice_0001</td>\n      <td>small_bowel</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>case123_day0_slice_0001</td>\n      <td>stomach</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>case123_day0_slice_0002</td>\n      <td>large_bowel</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>case123_day0_slice_0002</td>\n      <td>small_bowel</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2995</th>\n      <td>case77_day20_slice_0143</td>\n      <td>small_bowel</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>2996</th>\n      <td>case77_day20_slice_0143</td>\n      <td>stomach</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>2997</th>\n      <td>case77_day20_slice_0144</td>\n      <td>large_bowel</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>2998</th>\n      <td>case77_day20_slice_0144</td>\n      <td>small_bowel</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>2999</th>\n      <td>case77_day20_slice_0144</td>\n      <td>stomach</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#submit3.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:31.938300Z","iopub.execute_input":"2022-07-03T05:09:31.938554Z","iopub.status.idle":"2022-07-03T05:09:31.942930Z","shell.execute_reply.started":"2022-07-03T05:09:31.938526Z","shell.execute_reply":"2022-07-03T05:09:31.941571Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"submit4.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:21:44.663024Z","iopub.execute_input":"2022-07-03T05:21:44.663301Z","iopub.status.idle":"2022-07-03T05:21:45.343409Z","shell.execute_reply.started":"2022-07-03T05:21:44.663272Z","shell.execute_reply":"2022-07-03T05:21:45.342275Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"                        id       class4  \\\n0  case123_day0_slice_0001  large_bowel   \n1  case123_day0_slice_0001  small_bowel   \n2  case123_day0_slice_0001      stomach   \n3  case123_day0_slice_0002  large_bowel   \n4  case123_day0_slice_0002  small_bowel   \n\n                                          predicted4  \n0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class4</th>\n      <th>predicted4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>case123_day0_slice_0001</td>\n      <td>large_bowel</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>case123_day0_slice_0001</td>\n      <td>small_bowel</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>case123_day0_slice_0001</td>\n      <td>stomach</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>case123_day0_slice_0002</td>\n      <td>large_bowel</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>case123_day0_slice_0002</td>\n      <td>small_bowel</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submit5.iloc[146]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T06:04:35.776580Z","iopub.execute_input":"2022-07-03T06:04:35.776975Z","iopub.status.idle":"2022-07-03T06:04:35.856644Z","shell.execute_reply.started":"2022-07-03T06:04:35.776941Z","shell.execute_reply":"2022-07-03T06:04:35.855663Z"},"trusted":true},"execution_count":100,"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"id                                      case123_day0_slice_0049\nclass5                                                  stomach\npredicted5    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\nName: 146, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from scipy import stats","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:33.976043Z","iopub.execute_input":"2022-07-03T05:09:33.976941Z","iopub.status.idle":"2022-07-03T05:09:33.982219Z","shell.execute_reply.started":"2022-07-03T05:09:33.976893Z","shell.execute_reply":"2022-07-03T05:09:33.980958Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"a=np.array([submit1[\"predicted1\"],submit2[\"predicted2\"],submit3[\"predicted3\"],submit4[\"predicted4\"],submit5[\"predicted5\"]])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:22:10.240701Z","iopub.execute_input":"2022-07-03T05:22:10.240966Z","iopub.status.idle":"2022-07-03T05:22:10.246962Z","shell.execute_reply.started":"2022-07-03T05:22:10.240935Z","shell.execute_reply":"2022-07-03T05:22:10.245768Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weight=[0.2,0.2,0.2,0.2,0.2]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T06:02:19.069372Z","iopub.execute_input":"2022-07-03T06:02:19.069683Z","iopub.status.idle":"2022-07-03T06:02:19.076779Z","shell.execute_reply.started":"2022-07-03T06:02:19.069653Z","shell.execute_reply":"2022-07-03T06:02:19.075586Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"weighted_preds=np.tensordot(a,weight,axes=((0),(0)))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T06:02:19.800350Z","iopub.execute_input":"2022-07-03T06:02:19.800868Z","iopub.status.idle":"2022-07-03T06:02:32.914011Z","shell.execute_reply.started":"2022-07-03T06:02:19.800834Z","shell.execute_reply":"2022-07-03T06:02:32.912996Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(weighted_preds)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T06:03:43.580056Z","iopub.execute_input":"2022-07-03T06:03:43.580351Z","iopub.status.idle":"2022-07-03T06:03:43.588560Z","shell.execute_reply.started":"2022-07-03T06:03:43.580306Z","shell.execute_reply":"2022-07-03T06:03:43.587676Z"},"trusted":true},"execution_count":96,"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"rle_encode(weighted_preds)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T06:06:41.231907Z","iopub.execute_input":"2022-07-03T06:06:41.232446Z","iopub.status.idle":"2022-07-03T06:06:41.251180Z","shell.execute_reply.started":"2022-07-03T06:06:41.232380Z","shell.execute_reply":"2022-07-03T06:06:41.250129Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n  app.launch_new_instance()\n","output_type":"stream"},{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"'1'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#a = pd.DataFrame(list(a),columns=[\"predicted\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T06:07:55.136377Z","iopub.execute_input":"2022-07-03T06:07:55.136685Z","iopub.status.idle":"2022-07-03T06:07:55.141779Z","shell.execute_reply.started":"2022-07-03T06:07:55.136655Z","shell.execute_reply":"2022-07-03T06:07:55.140613Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"#a.iloc[146][0][0]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T06:07:55.878391Z","iopub.execute_input":"2022-07-03T06:07:55.878676Z","iopub.status.idle":"2022-07-03T06:07:55.882874Z","shell.execute_reply.started":"2022-07-03T06:07:55.878647Z","shell.execute_reply":"2022-07-03T06:07:55.881694Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"\"\"\"submits = []\nfor i in range(len(submit2)):\n    final_submit = (\n    submit2.iloc[i, :].predicted +\n    submit4.iloc[i, :].predicted )/ 2.0\n     \n    new_sub = (final_submit >= 0.5).astype('uint8')\n    classes = [submit2.iloc[i, :][\"class2\"],\n               submit4.iloc[i, :][\"class4\"]]\n    new_class = stats.mode(np.array(classes))[0][0]\n    \n    submits.append({ \"id\": submit2.iloc[i,:].id, \"class\": new_class, \"predicted\": rle_encode(new_sub) })\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-07-03T06:07:56.182721Z","iopub.execute_input":"2022-07-03T06:07:56.182989Z","iopub.status.idle":"2022-07-03T06:07:56.190159Z","shell.execute_reply.started":"2022-07-03T06:07:56.182958Z","shell.execute_reply":"2022-07-03T06:07:56.188977Z"},"trusted":true},"execution_count":105,"outputs":[{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"'submits = []\\nfor i in range(len(submit2)):\\n    final_submit = (\\n    submit2.iloc[i, :].predicted +\\n    submit4.iloc[i, :].predicted )/ 2.0\\n     \\n    new_sub = (final_submit >= 0.5).astype(\\'uint8\\')\\n    classes = [submit2.iloc[i, :][\"class2\"],\\n               submit4.iloc[i, :][\"class4\"]]\\n    new_class = stats.mode(np.array(classes))[0][0]\\n    \\n    submits.append({ \"id\": submit2.iloc[i,:].id, \"class\": new_class, \"predicted\": rle_encode(new_sub) })'"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"submit_df = pd.DataFrame(submits)\nsubmit_df\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.627363Z","iopub.status.idle":"2022-07-03T05:09:34.627882Z","shell.execute_reply.started":"2022-07-03T05:09:34.627604Z","shell.execute_reply":"2022-07-03T05:09:34.627631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#set(final_submit.flatten())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.630007Z","iopub.status.idle":"2022-07-03T05:09:34.634904Z","shell.execute_reply.started":"2022-07-03T05:09:34.634549Z","shell.execute_reply":"2022-07-03T05:09:34.634583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submit=pd.concat([submit1,submit2[\"class2\"],submit3[\"class3\"],submit4[\"class4\"],submit5[\"class5\"]],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.636678Z","iopub.status.idle":"2022-07-03T05:09:34.637181Z","shell.execute_reply.started":"2022-07-03T05:09:34.636905Z","shell.execute_reply":"2022-07-03T05:09:34.636932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submit","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.639966Z","iopub.status.idle":"2022-07-03T05:09:34.640552Z","shell.execute_reply.started":"2022-07-03T05:09:34.640200Z","shell.execute_reply":"2022-07-03T05:09:34.640246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nsubmit[\"class1\"]=le.fit_transform(submit[\"class1\"])\nsubmit[\"class2\"]=le.fit_transform(submit[\"class2\"])\nsubmit[\"class3\"]=le.fit_transform(submit[\"class3\"])\nsubmit[\"class4\"]=le.fit_transform(submit[\"class4\"])\nsubmit[\"class5\"]=le.fit_transform(submit[\"class5\"])\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.642435Z","iopub.status.idle":"2022-07-03T05:09:34.642985Z","shell.execute_reply.started":"2022-07-03T05:09:34.642691Z","shell.execute_reply":"2022-07-03T05:09:34.642720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submit","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.644643Z","iopub.status.idle":"2022-07-03T05:09:34.645194Z","shell.execute_reply.started":"2022-07-03T05:09:34.644875Z","shell.execute_reply":"2022-07-03T05:09:34.644901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from scipy import stats","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.646949Z","iopub.status.idle":"2022-07-03T05:09:34.648099Z","shell.execute_reply.started":"2022-07-03T05:09:34.647779Z","shell.execute_reply":"2022-07-03T05:09:34.647810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submit.apply(lambda x: stats.mode(np.array([x.class1, x.class2, x.class3, x.class4, x.class5]))[0][0], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.649854Z","iopub.status.idle":"2022-07-03T05:09:34.650398Z","shell.execute_reply.started":"2022-07-03T05:09:34.650092Z","shell.execute_reply":"2022-07-03T05:09:34.650120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X=submit","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.652083Z","iopub.status.idle":"2022-07-03T05:09:34.652972Z","shell.execute_reply.started":"2022-07-03T05:09:34.652665Z","shell.execute_reply":"2022-07-03T05:09:34.652709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y=submit[\"class5\"]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.654644Z","iopub.status.idle":"2022-07-03T05:09:34.655383Z","shell.execute_reply.started":"2022-07-03T05:09:34.655069Z","shell.execute_reply":"2022-07-03T05:09:34.655098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from lightgbm import LGBMClassifier as lgb","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.657666Z","iopub.status.idle":"2022-07-03T05:09:34.658352Z","shell.execute_reply.started":"2022-07-03T05:09:34.657980Z","shell.execute_reply":"2022-07-03T05:09:34.658052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X=X.drop([\"class5\",\"id\",\"predicted\"],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.660284Z","iopub.status.idle":"2022-07-03T05:09:34.660924Z","shell.execute_reply.started":"2022-07-03T05:09:34.660577Z","shell.execute_reply":"2022-07-03T05:09:34.660624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"from sklearn.model_selection import train_test_split\ntest_size_pct = 0.20\nX_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size = test_size_pct, random_state = 42)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.662956Z","iopub.status.idle":"2022-07-03T05:09:34.663498Z","shell.execute_reply.started":"2022-07-03T05:09:34.663203Z","shell.execute_reply":"2022-07-03T05:09:34.663231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_train","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.665351Z","iopub.status.idle":"2022-07-03T05:09:34.665939Z","shell.execute_reply.started":"2022-07-03T05:09:34.665632Z","shell.execute_reply":"2022-07-03T05:09:34.665665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model=lgb()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.667906Z","iopub.status.idle":"2022-07-03T05:09:34.668940Z","shell.execute_reply.started":"2022-07-03T05:09:34.668650Z","shell.execute_reply":"2022-07-03T05:09:34.668681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.670836Z","iopub.status.idle":"2022-07-03T05:09:34.671742Z","shell.execute_reply.started":"2022-07-03T05:09:34.671431Z","shell.execute_reply":"2022-07-03T05:09:34.671475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fix sub error, refers to: https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/discussion/320541\nif not debug:\n    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n    del sub_df['predicted']\n    sub_df = sub_df.merge(submit_df, on=['id','class'])\n    sub_df.to_csv('submission.csv',index=False)\nelse:\n    submit_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T05:09:34.673512Z","iopub.status.idle":"2022-07-03T05:09:34.674010Z","shell.execute_reply.started":"2022-07-03T05:09:34.673740Z","shell.execute_reply":"2022-07-03T05:09:34.673769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}