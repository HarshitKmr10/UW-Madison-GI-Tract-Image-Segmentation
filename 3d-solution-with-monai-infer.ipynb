{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Load Libs","metadata":{}},{"cell_type":"code","source":"import sys\n\nsys.path.append('../input/monai-v081/')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:45:16.739219Z","iopub.execute_input":"2022-06-27T05:45:16.740275Z","iopub.status.idle":"2022-06-27T05:45:16.776584Z","shell.execute_reply.started":"2022-06-27T05:45:16.740127Z","shell.execute_reply":"2022-06-27T05:45:16.775768Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import gc\nfrom glob import glob\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom monai.inferers import sliding_window_inference\nfrom monai.data import decollate_batch\nfrom monai.handlers.utils import from_engine\nfrom monai.networks.nets import UNet\nfrom torch.cuda.amp import GradScaler, autocast\nfrom tqdm import tqdm\nimport json","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:45:16.839722Z","iopub.execute_input":"2022-06-27T05:45:16.840183Z","iopub.status.idle":"2022-06-27T05:45:24.773052Z","shell.execute_reply.started":"2022-06-27T05:45:16.840144Z","shell.execute_reply":"2022-06-27T05:45:24.772160Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"WANDB\")\n    wandb.login(key=api_key)\n    anonymous = None\nexcept:\n    anonymous = \"must\"\n    print('To use your W&B account,\\nGo to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \\nGet your W&B access token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:45:24.775210Z","iopub.execute_input":"2022-06-27T05:45:24.775494Z","iopub.status.idle":"2022-06-27T05:45:26.284619Z","shell.execute_reply.started":"2022-06-27T05:45:24.775434Z","shell.execute_reply":"2022-06-27T05:45:26.283642Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"from monai.data import CacheDataset, DataLoader\nfrom monai.transforms import (\n    Compose,\n    Activations,\n    AsDiscrete,\n    Activationsd,\n    AsDiscreted,\n    KeepLargestConnectedComponentd,\n    Invertd,\n    LoadImage,\n    Transposed,\n    LoadImaged,\n    AddChanneld,\n    CastToTyped,\n    Lambdad,\n    Resized,\n    EnsureTyped,\n    SpatialPadd,\n    EnsureChannelFirstd,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:45:26.286510Z","iopub.execute_input":"2022-06-27T05:45:26.287200Z","iopub.status.idle":"2022-06-27T05:45:26.293285Z","shell.execute_reply.started":"2022-06-27T05:45:26.287148Z","shell.execute_reply":"2022-06-27T05:45:26.292510Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Prepare meta info.","metadata":{}},{"cell_type":"markdown","source":"### Thanks awsaf49, this section refers to:\nhttps://www.kaggle.com/code/awsaf49/uwmgi-2-5d-infer-pytorch","metadata":{}},{"cell_type":"code","source":"def get_metadata(row):\n    data = row['id'].split('_')\n    case = int(data[0].replace('case',''))\n    day = int(data[1].replace('day',''))\n    slice_ = int(data[-1])\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row\n\ndef path2info(row):\n    path = row['image_path']\n    data = path.split('/')\n    slice_ = int(data[-1].split('_')[1])\n    case = int(data[-3].split('_')[0].replace('case',''))\n    day = int(data[-3].split('_')[1].replace('day',''))\n    width = int(data[-1].split('_')[2])\n    height = int(data[-1].split('_')[3])\n    row['height'] = height\n    row['width'] = width\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:45:26.296059Z","iopub.execute_input":"2022-06-27T05:45:26.296623Z","iopub.status.idle":"2022-06-27T05:45:26.307957Z","shell.execute_reply.started":"2022-06-27T05:45:26.296585Z","shell.execute_reply":"2022-06-27T05:45:26.307139Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\nif not len(sub_df):\n    debug = True\n    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')[:1000*3]\n    sub_df = sub_df.drop(columns=['class','segmentation']).drop_duplicates()\nelse:\n    debug = False\n    sub_df = sub_df.drop(columns=['class','predicted']).drop_duplicates()\nsub_df = sub_df.apply(lambda x: get_metadata(x),axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:45:26.309976Z","iopub.execute_input":"2022-06-27T05:45:26.310908Z","iopub.status.idle":"2022-06-27T05:45:28.760831Z","shell.execute_reply.started":"2022-06-27T05:45:26.310866Z","shell.execute_reply":"2022-06-27T05:45:28.759915Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"if debug:\n    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/train/**/*png',recursive=True)\n#     paths = sorted(paths)\nelse:\n    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/test/**/*png',recursive=True)\n#     paths = sorted(paths)\npath_df = pd.DataFrame(paths, columns=['image_path'])\npath_df = path_df.apply(lambda x: path2info(x),axis=1)\npath_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:45:28.762197Z","iopub.execute_input":"2022-06-27T05:45:28.762505Z","iopub.status.idle":"2022-06-27T05:47:08.258326Z","shell.execute_reply.started":"2022-06-27T05:45:28.762435Z","shell.execute_reply":"2022-06-27T05:47:08.257606Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                          image_path  height  width  case  \\\n0  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n1  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n2  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n3  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n4  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n\n   day  slice  \n0   14      6  \n1   14     82  \n2   14    113  \n3   14     76  \n4   14    125  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>height</th>\n      <th>width</th>\n      <th>case</th>\n      <th>day</th>\n      <th>slice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n      <td>266</td>\n      <td>266</td>\n      <td>36</td>\n      <td>14</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n      <td>266</td>\n      <td>266</td>\n      <td>36</td>\n      <td>14</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n      <td>266</td>\n      <td>266</td>\n      <td>36</td>\n      <td>14</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n      <td>266</td>\n      <td>266</td>\n      <td>36</td>\n      <td>14</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n      <td>266</td>\n      <td>266</td>\n      <td>36</td>\n      <td>14</td>\n      <td>125</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Produce 3d data list for MONAI DataSet","metadata":{}},{"cell_type":"code","source":"test_df = sub_df.merge(path_df, on=['case','day','slice'], how='left')\ntest_df[\"case_id_str\"] = test_df[\"id\"].apply(lambda x: x.split(\"_\", 2)[0])\ntest_df[\"day_num_str\"] = test_df[\"id\"].apply(lambda x: x.split(\"_\", 2)[1])\ntest_df[\"slice_id\"] = test_df[\"id\"].apply(lambda x: x.split(\"_\", 2)[2])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:47:08.259667Z","iopub.execute_input":"2022-06-27T05:47:08.260080Z","iopub.status.idle":"2022-06-27T05:47:08.289999Z","shell.execute_reply.started":"2022-06-27T05:47:08.260041Z","shell.execute_reply":"2022-06-27T05:47:08.289246Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_data = []\n\nfor group in test_df.groupby([\"case_id_str\", \"day_num_str\"]):\n\n    case_id_str, day_num_str = group[0]\n    group_id = case_id_str + \"_\" + day_num_str\n    group_df = group[1].sort_values(\"slice_id\", ascending=True)\n    n_slices = group_df.shape[0]\n    group_slices, group_ids = [], []\n    for idx in range(n_slices):\n        slc = group_df.iloc[idx]\n        group_slices.append(slc.image_path)\n        group_ids.append(slc.id)\n    test_data.append({\"image\": group_slices, \"id\": group_ids})","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:47:08.291415Z","iopub.execute_input":"2022-06-27T05:47:08.291810Z","iopub.status.idle":"2022-06-27T05:47:08.441090Z","shell.execute_reply.started":"2022-06-27T05:47:08.291774Z","shell.execute_reply":"2022-06-27T05:47:08.440256Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Transforms, Dataset, DataLoader","metadata":{}},{"cell_type":"code","source":"class cfg:\n    img_size = (224, 224, 80)\n    in_channels = 1\n    out_channels = 3\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    weights = glob(\"../input/uw3dweights/large*\")\n    batch_size = 1\n    sw_batch_size = 4","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:47:08.442596Z","iopub.execute_input":"2022-06-27T05:47:08.442883Z","iopub.status.idle":"2022-06-27T05:47:08.512433Z","shell.execute_reply.started":"2022-06-27T05:47:08.442829Z","shell.execute_reply":"2022-06-27T05:47:08.511406Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\"\"\"for i in cfg.weights:\n    print(torch.load(i))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:47:08.516264Z","iopub.execute_input":"2022-06-27T05:47:08.516539Z","iopub.status.idle":"2022-06-27T05:47:08.522078Z","shell.execute_reply.started":"2022-06-27T05:47:08.516485Z","shell.execute_reply":"2022-06-27T05:47:08.521213Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'for i in cfg.weights:\\n    print(torch.load(i))'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transforms = Compose(\n    [\n        LoadImaged(keys=\"image\"), # d, h, w\n        AddChanneld(keys=\"image\"), # c, d, h, w\n        Transposed(keys=\"image\", indices=[0, 2, 3, 1]), # c, w, h, d\n        Lambdad(keys=\"image\", func=lambda x: x / x.max()),\n#         SpatialPadd(keys=\"image\", spatial_size=cfg.img_size),  # in case less than 80 slices\n        EnsureTyped(keys=\"image\", dtype=torch.float32),\n    ]\n)\n\ntest_ds = CacheDataset(\n        data=test_data,\n        transform=test_transforms,\n        cache_rate=0.0,\n        num_workers=2,\n    )\n\ntest_dataloader = DataLoader(\n    test_ds,\n    batch_size=cfg.batch_size,\n    num_workers=2,\n    pin_memory=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:47:08.523379Z","iopub.execute_input":"2022-06-27T05:47:08.524009Z","iopub.status.idle":"2022-06-27T05:47:08.536451Z","shell.execute_reply.started":"2022-06-27T05:47:08.523933Z","shell.execute_reply":"2022-06-27T05:47:08.535720Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Network","metadata":{}},{"cell_type":"code","source":"model = UNet(\n    spatial_dims=3,\n    in_channels=cfg.in_channels,\n    out_channels=cfg.out_channels,\n    channels=(32, 64, 128, 256, 512),\n    strides=(2, 2, 2, 2),\n    kernel_size=3,\n    up_kernel_size=3,\n    num_res_units=2,\n    act=\"PRELU\",\n    norm=\"BATCH\",\n    dropout=0.2,\n    bias=True,\n    dimensions=None,\n).to(cfg.device)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:47:08.539929Z","iopub.execute_input":"2022-06-27T05:47:08.540132Z","iopub.status.idle":"2022-06-27T05:47:12.573287Z","shell.execute_reply.started":"2022-06-27T05:47:08.540106Z","shell.execute_reply":"2022-06-27T05:47:12.572517Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Infer","metadata":{}},{"cell_type":"code","source":"# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    \"\"\" TBD\n    \n    Args:\n        img (np.array): \n            - 1 indicating mask\n            - 0 indicating background\n    \n    Returns: \n        run length as string formated\n    \"\"\"\n    \n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:47:12.574825Z","iopub.execute_input":"2022-06-27T05:47:12.575120Z","iopub.status.idle":"2022-06-27T05:47:12.583132Z","shell.execute_reply.started":"2022-06-27T05:47:12.575082Z","shell.execute_reply":"2022-06-27T05:47:12.582327Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"outputs = []\n\npost_pred = Compose([\n    Activations(sigmoid=True),\n    AsDiscrete(threshold=0.5)\n])\n\nmodel.eval()\ntorch.set_grad_enabled(False)\nprogress_bar = tqdm(range(len(test_dataloader)))\nval_it = iter(test_dataloader)\nfor itr in progress_bar:\n    batch = next(val_it)\n    test_inputs = batch[\"image\"].to(cfg.device)\n\n    pred_all = []\n    for weights in cfg.weights:\n        model.load_state_dict(torch.load(weights))\n        pred = sliding_window_inference(test_inputs, cfg.img_size, cfg.sw_batch_size, model)\n        pred_all.append(pred)\n        # do 4 tta\n        for dims in [[2], [3], [2, 3]]:\n            flip_pred = sliding_window_inference(torch.flip(test_inputs, dims=dims), cfg.img_size, cfg.sw_batch_size, model)\n            flip_pred = torch.flip(flip_pred, dims=dims)\n            pred_all.append(flip_pred)\n    pred_all = torch.mean(torch.stack(pred_all), dim=0)[0]\n    pred_all = post_pred(pred_all)\n    # c, w, h, d to d, c, h, w\n    pred_all = torch.permute(pred_all, [3, 0, 2, 1]).cpu().numpy().astype(np.uint8)\n    id_outputs = from_engine([\"id\"])(batch)[0]\n\n    for test_output, id_output in zip(pred_all, id_outputs):\n        id_name = id_output[0]\n        lb, sb, st = test_output\n        outputs.append([id_name, \"large_bowel\", rle_encode(lb)])\n        outputs.append([id_name, \"small_bowel\", rle_encode(sb)])\n        outputs.append([id_name, \"stomach\", rle_encode(st)])\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:47:12.584679Z","iopub.execute_input":"2022-06-27T05:47:12.584984Z","iopub.status.idle":"2022-06-27T05:47:41.527723Z","shell.execute_reply.started":"2022-06-27T05:47:12.584946Z","shell.execute_reply":"2022-06-27T05:47:41.526655Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"100%|██████████| 7/7 [00:28<00:00,  4.13s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.DataFrame(data=np.array(outputs), columns=[\"id\", \"class\", \"predicted\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:47:41.530454Z","iopub.execute_input":"2022-06-27T05:47:41.530801Z","iopub.status.idle":"2022-06-27T05:47:41.593172Z","shell.execute_reply.started":"2022-06-27T05:47:41.530757Z","shell.execute_reply":"2022-06-27T05:47:41.592260Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Fix sub error, refers to: https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/discussion/320541\nif not debug:\n    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n    del sub_df['predicted']\n    sub_df = sub_df.merge(submit, on=['id','class'])\n    sub_df.to_csv('submission.csv',index=False)\nelse:\n    submit.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:47:41.594486Z","iopub.execute_input":"2022-06-27T05:47:41.594869Z","iopub.status.idle":"2022-06-27T05:47:41.636088Z","shell.execute_reply.started":"2022-06-27T05:47:41.594830Z","shell.execute_reply":"2022-06-27T05:47:41.635433Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}